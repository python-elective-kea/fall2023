Session 5 - Utilities and Modules
=================================

Today, we will continue working with modules, focusing specifically on the third-party module BeautifulSoup for web scraping. Additionally, you will learn how to persistently save your installed modules (done using pip install) and save your requirements for version control of your projects packages.


.. note::
        In an earlier version of this session document docker was a big part of it. If you already started looking at this and would like to cary on you can find it `here <_ses5.rst>`_


Learning goals
--------------
After this week you will be able to:
       
        - Use python build in modules.
        - Find and use 3rd party modules.
        - Save and Share your projects dependencies.
        - work with markdown documents.
        - Work with the module BeautifullSoup for webscrabing.


Materials
---------
* `Notebook from teachings <notebooks/notes_docker_requirements_webscrabing.ipynb>`_
* `Best pratice - working in teams with docker, github <notebooks/best_practice_docker_github.ipynb>`_
* `Beautiful Soup Documentation <https://www.crummy.com/software/BeautifulSoup/bs4/doc/>`_
* `Code examples from today <https://github.com/python-elective-kea/fall2023-code-examples-from-teachings/tree/master/ses5>`_



Exercises
---------





------
Python
------

Ex 5: Build a Web Scraper With Python
*************************************

`Solution <exercises/solution/04_modules/solutions.rst>`_

1. `Build a Web Scraper With Python <https://realpython.com/beautiful-soup-web-scraper-python/>`_
2. Find all relevant python jobs on this website: `jobnet.dk <https://job.jobnet.dk/CV>`_ or `jobindex.dk <https://www.jobindex.dk/?lang=dk>`_


Ex 6: Simple scraber with requests (and BS)
*******************************************

Do the `Ex 7: Simple scraber with requests <week37.rst#ex-7-simple-scraber-with-requests>`_ exercise from last week but now also by using the BeautifullSoup module.


